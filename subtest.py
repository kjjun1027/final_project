import numpy as np
import os
import pandas as pd
import pickle
import cv2
import logging
import sys
import matplotlib.pyplot as plt
from scipy.signal import find_peaks, savgol_filter
from sklearn.metrics.pairwise import cosine_similarity
from dtaidistance import dtw
from sklearn.preprocessing import normalize
from collections import defaultdict
from src.processing import extract_landmarks
from matplotlib.animation import FuncAnimation
import matplotlib
import matplotlib.font_manager as fm
from scipy.interpolate import interp1d
import json
import mediapipe as mp
plt.rcParams['font.family'] = 'DejaVu Sans'
matplotlib.rcParams['axes.unicode_minus'] = False
font_path = "C:/Windows/Fonts/malgun.ttf"
font_prop = fm.FontProperties(fname=font_path)
matplotlib.rc('font', family=font_prop.get_name())

# 1. CSV ë°ì´í„° ë¡œë”© ë° 3D ì¢Œí‘œ ë³€í™˜
def load_and_process_csv(csv_path):
    try:
        df = pd.read_csv(csv_path)
        if df.empty:
            logging.error("âŒ CSV íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return None
        if not all([f'landmark_{i}_x' in df.columns for i in range(33)]):
            logging.error("âŒ CSV íŒŒì¼ì— í•„ìˆ˜ ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        logging.error(f"âŒ CSV íŒŒì¼ ë¡œë”© ì˜¤ë¥˜: {str(e)}")
        return None

    logging.info(f"âœ… CSV íŒŒì¼ ë¡œë”© ì„±ê³µ: {csv_path}")
    logging.info(f"ğŸ“Š ë°ì´í„°í”„ë ˆì„ ì •ë³´: {df.head()}")
    
    # ê¸°ì¡´ ì²˜ë¦¬ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€
    rename_mapping_x = {f"joint_{i}": f"landmark_{i}_x" for i in range(33)}
    rename_mapping_y = {f"joint_{i+33}": f"landmark_{i}_y" for i in range(33)}
    rename_mapping_z = {f"joint_{i+66}": f"landmark_{i}_z" for i in range(33)}
    df.rename(columns=rename_mapping_x, inplace=True)
    df.rename(columns=rename_mapping_y, inplace=True)
    df.rename(columns=rename_mapping_z, inplace=True)

    coordinate_cols = [col for col in df.columns if '_x' in col or '_y' in col or '_z' in col]
    df[coordinate_cols] = df[coordinate_cols].apply(pd.to_numeric, errors='coerce')

    df.interpolate(method='linear', axis=0, inplace=True)
    df.fillna(df.mean(), inplace=True)
    df.fillna(0, inplace=True)
    
    return df

# 2. ê´€ì ˆ ê°ë„ ê³„ì‚°
def compute_angle(a, b, c):
    ba = np.array(a) - np.array(b)
    bc = np.array(c) - np.array(b)
    norm_ba = np.linalg.norm(ba)
    norm_bc = np.linalg.norm(bc)
    if norm_ba == 0 or norm_bc == 0:
        return 0.0
    dot_product = np.dot(ba, bc)
    cosine_angle = np.clip(dot_product / (norm_ba * norm_bc), -1.0, 1.0)
    return np.degrees(np.arccos(cosine_angle))

def compute_joint_angles_with_derivatives(df):
    """
    3D ì¢Œí‘œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 10ê°œ ê´€ì ˆì˜ ê°ë„, ì†ë„, ê°€ì†ë„ë¥¼ ê³„ì‚°
    """
    joint_angles = []
    for _, row in df.iterrows():
        frame_landmarks = [(row[f'landmark_{i}_x'], row[f'landmark_{i}_y'], row[f'landmark_{i}_z'])
                           for i in range(33)]
        left_knee = compute_angle(frame_landmarks[23], frame_landmarks[25], frame_landmarks[27])
        right_knee = compute_angle(frame_landmarks[24], frame_landmarks[26], frame_landmarks[28])
        left_elbow = compute_angle(frame_landmarks[11], frame_landmarks[13], frame_landmarks[15])
        right_elbow = compute_angle(frame_landmarks[12], frame_landmarks[14], frame_landmarks[16])
        left_shoulder = compute_angle(frame_landmarks[13], frame_landmarks[11], frame_landmarks[23])
        right_shoulder = compute_angle(frame_landmarks[14], frame_landmarks[12], frame_landmarks[24])
        left_hip = compute_angle(frame_landmarks[11], frame_landmarks[23], frame_landmarks[25])
        right_hip = compute_angle(frame_landmarks[12], frame_landmarks[24], frame_landmarks[26])
        left_ankle = compute_angle(frame_landmarks[25], frame_landmarks[27], frame_landmarks[29])
        right_ankle = compute_angle(frame_landmarks[26], frame_landmarks[28], frame_landmarks[30])

        joint_angles.append([left_knee, right_knee, left_elbow, right_elbow,
                             left_shoulder, right_shoulder, left_hip, right_hip,
                             left_ankle, right_ankle])

    joint_angles = np.array(joint_angles)

    #ì†ë„ ë° ê°€ì†ë„ ê³„ì‚° ì¶”ê°€
    velocity = np.gradient(joint_angles, axis=0)
    acceleration = np.gradient(velocity, axis=0)

    return joint_angles, velocity, acceleration
    

# 3. ìš´ë™ íšŸìˆ˜ ë¶„ì„
def detect_repetition_intervals(angle_features, velocity_features, acceleration_features, min_frames=30, 
                                prominence=1, smoothing_window=15):
    """
        ê°ë„ ë³€í™”ëŸ‰ ê¸°ë°˜ìœ¼ë¡œ 0 -> 1 -> 0 ë°˜ë³µì„ ê°ì§€í•˜ì—¬ ìš´ë™ íšŸìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    - ê°ë„ ë³€í™”ëŸ‰ì˜ ìµœëŒ€ê°’(1)ê³¼ ìµœì†Œê°’(0) ì‚¬ì´ë¥¼ ë°˜ë³µìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
    - ë…¸ì´ì¦ˆ ì œê±° í•„í„°(Savitzky-Golay)ë¥¼ ì¶”ê°€í•˜ì—¬ ì •í™•ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.
    """
    total_frames = len(angle_features)
    if total_frames < min_frames:
        return [(0, total_frames)]  # ë„ˆë¬´ ì§§ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë°˜ë³µìœ¼ë¡œ ì²˜ë¦¬

    # ê°ë„, ì†ë„, ê°€ì†ë„ì˜ ë³€í™”ëŸ‰ì„ ê°ê° ê³„ì‚°
    avg_angles = np.mean(angle_features, axis=1)
    avg_velocity = np.linalg.norm(velocity_features, axis=1)
    avg_acceleration = np.linalg.norm(acceleration_features, axis=1)
    
    # ê°ë„ ë³€í™”ëŸ‰ ê³„ì‚°
    angle_differences = np.abs(np.gradient(avg_angles))
    
    # ë…¸ì´ì¦ˆ ì œê±° (Savitzky-Golay í•„í„°)
    if smoothing_window > 1 and smoothing_window < total_frames:
        angle_differences = savgol_filter(angle_differences, smoothing_window, polyorder=3)
    
    # ì†ë„ ë° ê°€ì†ë„ì˜ í‰ê· ê°’ ê³„ì‚°
    mean_velocity = np.mean(avg_velocity)
    mean_acceleration = np.mean(avg_acceleration)

    # ê¸°ì¤€ì„  ì´ìƒì¸ ê°’ë§Œ ì¶”ì¶œ (ì†ë„ ë° ê°€ì†ë„ì˜ 0.4 ë°° ì´ìƒì¸ ê²ƒë§Œ)
    valid_indices = np.where((avg_velocity > 0.4 * mean_velocity) | (avg_acceleration > 0.4 * mean_acceleration))[0]
    angle_differences_filtered = np.zeros_like(angle_differences)
    angle_differences_filtered[valid_indices] = angle_differences[valid_indices]
    
    # í”¼í¬ì™€ ê³¨ì§œê¸° ê°ì§€
    peaks, _ = find_peaks(angle_differences_filtered, prominence=prominence, distance=min_frames)
    valleys, _ = find_peaks(-angle_differences_filtered, prominence=prominence, distance=min_frames)
    
    # ë°˜ë³µ êµ¬ê°„ ê°ì§€ (0 -> 1 -> 0)
    intervals = []
    i = 0
    while i < len(valleys) - 1:
        start = valleys[i]
        end = valleys[i + 1]
        
        peaks_in_range = [p for p in peaks if start < p < end]
        
        if len(peaks_in_range) > 0:
            intervals.append((start, end))
        
        i += 1

    logging.info(f"ğŸ” ê²€ì¶œëœ ìš´ë™ ë°˜ë³µ ìˆ˜: {len(intervals)}")
    return intervals

# 4. ê° ë°˜ë³µì„ ë‹¨ê³„ë³„ë¡œ ë¶„ë¥˜ (ì •í™•ë„ ìµœì í™”)
def classify_phases(joint_features, velocity_features, acceleration_features, 
                    cluster_centers, ideal_phase_lengths, ideal_trajectory):
    """
    ë‹¨ê³„ ë¶„ë¥˜: ì´ìƒì  ê¶¤ì ì˜ ë‹¨ê³„ ë°°ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘.
    """
    min_len = min(len(joint_features), len(ideal_trajectory))
    ideal_phases_resampled = np.interp(
        np.linspace(0, 1, min_len),
        np.linspace(0, 1, len(ideal_trajectory)),
        ideal_trajectory
    ).round().astype(int)

    num_phases = len(np.unique(ideal_phases_resampled))
    
    computed_progress = [
        np.sum(ideal_phases_resampled == p) / min_len for p in range(num_phases)
    ]

    phase_frames = [{"phase": p, "indices": np.where(ideal_phases_resampled == p)[0]}
                    for p in range(num_phases)]

    return ideal_phases_resampled.tolist(), computed_progress, phase_frames


# 5. ì´ìƒì  ê¶¤ì ê³¼ ë¹„êµ & ìœ ì‚¬ë„ ê³„ì‚° (ì •í™•ë„ ìµœì í™”, L2 ê±°ë¦¬ ì‚¬ìš©)
def compare_phase_similarity(computed_phases, ideal_phases, 
                             computed_velocities, ideal_velocities, 
                             computed_accelerations, ideal_accelerations,
                             computed_progress, ideal_phase_progress, 
                             phase_transitions,
                             actual_trajectory_points, ideal_trajectory_points):
    """
    ì •í™•í•˜ê³  ê°„ë‹¨í•œ ë‹¨ê³„ ë¹„êµ ë° DTW ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°.
    """
    min_length = min(len(computed_phases), len(ideal_phases))
    computed_phases = computed_phases[:min_length]
    ideal_phases = ideal_phases[:min_length]

    # DTW ìœ ì‚¬ë„
    dtw_distance = dtw.distance(computed_phases, ideal_phases)
    dtw_similarity = 1 / (1 + dtw_distance / min_length)

    # Phase ì •í™•ë„
    phase_accuracy = np.mean(np.array(computed_phases) == np.array(ideal_phases))

    # ë‹¨ê³„ ì „í™˜ ì •í™•ë„
    computed_transitions = np.where(np.diff(computed_phases) != 0)[0]
    ideal_transitions = np.where(np.diff(ideal_phases) != 0)[0]
    transition_accuracy = 1 / (1 + np.mean([abs(ct - it) for ct, it in zip(computed_transitions, ideal_transitions)])) if computed_transitions.size and ideal_transitions.size else 1

    # ì†ë„ ë° ê°€ì†ë„ ìœ ì‚¬ë„
    velocity_similarity = 1 / (1 + np.mean(np.linalg.norm(computed_velocities - ideal_velocities[ideal_phases], axis=1)))
    acceleration_similarity = 1 / (1 + np.mean(np.linalg.norm(computed_accelerations - ideal_accelerations[ideal_phases], axis=1)))

    # ì§„í–‰ë¥  ì •í™•ë„
    progress_similarity = 1 - np.mean(np.abs(np.array(computed_progress) - np.array(ideal_phase_progress)))

    # ì „í™˜ ì ìˆ˜
    transition_score = np.mean([
        1 / (1 + phase_transitions[k]["angle_change"] +
             phase_transitions[k]["velocity_change"] +
             phase_transitions[k]["acceleration_change"])
        for k in phase_transitions
    ]) if phase_transitions else 1

    # 7. ìµœì¢… ìœ ì‚¬ë„ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì¡°ì •)
    total_similarity = (0.35 * dtw_similarity +            # DTW ê¸°ë°˜ ìœ ì‚¬ë„ (ì „ì²´ ê¶¤ì ì˜ íŒ¨í„´ ë¹„êµ)
                        0.2 * phase_accuracy +            # ë‹¨ê³„ ì •í™•ë„
                        0.15 * transition_accuracy +      # ë‹¨ê³„ ì „í™˜ ì •í™•ë„
                        0.1 * velocity_similarity +       # ì†ë„ ìœ ì‚¬ë„
                        0.1 * acceleration_similarity +   # ê°€ì†ë„ ìœ ì‚¬ë„
                        0.1 * progress_similarity)         # ì§„í–‰ë¥  ìœ ì‚¬ë„

    print(f"âœ… ìœ ì‚¬ë„: {total_similarity * 100:.2f}% (ê¶¤ì  ìœ ì‚¬ë„: {dtw_similarity * 100:.2f}%, "
          f"ë‹¨ê³„ ì •í™•ë„: {phase_accuracy * 100:.2f}%, "
          f"ì „í™˜ ì •í™•ë„: {transition_accuracy * 100:.2f}%, "
          f"ì†ë„ ìœ ì‚¬ë„: {velocity_similarity * 100:.2f}%, "
          f"ê°€ì†ë„ ìœ ì‚¬ë„: {acceleration_similarity * 100:.2f}%, "
          f"ì§„í–‰ë¥  ìœ ì‚¬ë„: {progress_similarity * 100:.2f}%, "
          f"ë‹¨ê³„ ì „í™˜ ë³€í™”ëŸ‰ ìœ ì‚¬ë„: {transition_score} ")

    return total_similarity * 100

# 6. ì˜ìƒ ì¶œë ¥
def extract_first_frame_landmarks(df, segment):
    """
    ê° ìš´ë™ ë°˜ë³µ êµ¬ê°„ì˜ ì²« ë²ˆì§¸ í”„ë ˆì„ì—ì„œ ì£¼ìš” ê´€ì ˆì˜ ì¢Œí‘œë¥¼ ì¶”ì¶œí•˜ê³  ê´€ì ˆ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    try:
        start_frame = segment[0]
        if start_frame >= len(df):
            logging.error(f"âŒ ì˜ëª»ëœ í”„ë ˆì„ ì¸ë±ìŠ¤: {start_frame}. ë°ì´í„° í”„ë ˆì„ì˜ ê¸¸ì´: {len(df)}")
            return None  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  None ë°˜í™˜

        # ê´€ì ˆ ì¢Œí‘œ ì¶”ì¶œ (33ê°œ ëª¨ë“  ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°)
        frame_landmarks = [(df[f'landmark_{i}_x'].iloc[start_frame], 
                            df[f'landmark_{i}_y'].iloc[start_frame], 
                            df[f'landmark_{i}_z'].iloc[start_frame]) 
                           for i in range(33)]

        if not frame_landmarks:
            logging.error(f"âŒ í”„ë ˆì„ {start_frame}ì—ì„œ ê´€ì ˆ ì¢Œí‘œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None

        # ì£¼ìš” ê´€ì ˆ ê°ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜
        left_knee = compute_angle(frame_landmarks[23], frame_landmarks[25], frame_landmarks[27])
        right_knee = compute_angle(frame_landmarks[24], frame_landmarks[26], frame_landmarks[28])
        left_elbow = compute_angle(frame_landmarks[11], frame_landmarks[13], frame_landmarks[15])
        right_elbow = compute_angle(frame_landmarks[12], frame_landmarks[14], frame_landmarks[16])
        left_shoulder = compute_angle(frame_landmarks[13], frame_landmarks[11], frame_landmarks[23])
        right_shoulder = compute_angle(frame_landmarks[14], frame_landmarks[12], frame_landmarks[24])
        left_hip = compute_angle(frame_landmarks[11], frame_landmarks[23], frame_landmarks[25])
        right_hip = compute_angle(frame_landmarks[12], frame_landmarks[24], frame_landmarks[26])
        left_ankle = compute_angle(frame_landmarks[25], frame_landmarks[27], frame_landmarks[29])
        right_ankle = compute_angle(frame_landmarks[26], frame_landmarks[28], frame_landmarks[30])

        key_angles = [
            left_knee, right_knee, left_elbow, right_elbow,
            left_shoulder, right_shoulder, left_hip, right_hip,
            left_ankle, right_ankle
        ]
        
        logging.info(f"âœ… ì£¼ìš” ê´€ì ˆ ê°ë„ ì¶”ì¶œ ì„±ê³µ (í”„ë ˆì„: {start_frame})")
        return key_angles
    except Exception as e:
        logging.error(f"âŒ ì£¼ìš” ê´€ì ˆ ì¢Œí‘œ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None


def test_generate_ideal_trajectory(first_frame_angles, ideal_angles, ideal_velocities, ideal_accelerations, ideal_progress):
    """
    ì´ˆê¸° ê°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ìƒì  ê¶¤ì ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if first_frame_angles is None:
        logging.error("âŒ ì´ˆê¸° ê°ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    ideal_trajectory = [first_frame_angles]

    for t, (angle_set, velocity_set, acceleration_set) in enumerate(zip(ideal_angles, ideal_velocities, ideal_accelerations)):
        new_frame_angles = []

        progress_factor = ideal_progress[t] if t < len(ideal_progress) else 1.0

        for j, base_angle in enumerate(first_frame_angles):
            angle_change = angle_set[j % len(angle_set)] * progress_factor
            velocity_change = velocity_set[j % len(velocity_set)] * progress_factor
            acceleration_change = acceleration_set[j % len(acceleration_set)] * progress_factor

            new_angle = base_angle + angle_change + velocity_change * 0.01 + acceleration_change * 0.001
            new_frame_angles.append(new_angle)
        
        ideal_trajectory.append(new_frame_angles)

    return ideal_trajectory

def plot_trajectory_comparison(
    actual_trajectory,            # numpy array (í”„ë ˆì„ x ê´€ì ˆ)
    ideal_trajectory,             # numpy array (í”„ë ˆì„ x ê´€ì ˆ)
    save_path,                    # ì €ì¥ ê²½ë¡œ
    exercise_name="Exercise"      # ìš´ë™ ì´ë¦„
):

    actual_trajectory = np.array(actual_trajectory)
    ideal_trajectory = np.array(ideal_trajectory)

    # 1. ê°ë„, ì†ë„, ê°€ì†ë„ ê³„ì‚°
    actual_velocity = np.gradient(actual_trajectory, axis=0)
    ideal_velocity = np.gradient(ideal_trajectory, axis=0)

    actual_acceleration = np.gradient(actual_velocity, axis=0)
    ideal_acceleration = np.gradient(ideal_velocity, axis=0)

    # 2. ë‹¨ê³„ ì„ì˜ ì¶”ì •
    phase_actual = estimate_phases(actual_trajectory)
    phase_ideal = estimate_phases(ideal_trajectory)

    # 3. ë‹¨ê³„ ì „í™˜ ë³€í™”ëŸ‰
    transition_actual = np.abs(np.diff(actual_trajectory, axis=0))
    transition_ideal = np.abs(np.diff(ideal_trajectory, axis=0))
    avg_actual_transition = np.mean(transition_actual, axis=1)
    avg_ideal_transition = np.mean(transition_ideal, axis=1)

    # 4. ê°ë„ ë³€í™”ëŸ‰ (Angle Change Rate)
    angle_change_actual = np.linalg.norm(np.diff(actual_trajectory, axis=0), axis=1)
    angle_change_ideal = np.linalg.norm(np.diff(ideal_trajectory, axis=0), axis=1)

    x = np.arange(len(actual_trajectory))

    fig, axes = plt.subplots(5, 1, figsize=(16, 20), sharex=True)

    # 1. Phase ë¹„êµ
    axes[0].plot(x, phase_actual, label="Actual Phase", color='blue')
    axes[0].plot(x, phase_ideal, label="Ideal Phase", color='red', linestyle='--')
    axes[0].set_title("Phase Comparison")
    axes[0].legend()
    axes[0].grid(True)

    # 2. ì†ë„ í‰ê· 
    axes[1].plot(x, np.mean(actual_velocity, axis=1), label="Actual", color='blue')
    axes[1].plot(x, np.mean(ideal_velocity, axis=1), label="Ideal", color='red', linestyle='--')
    axes[1].set_title("Velocity Comparison")
    axes[1].legend()
    axes[1].grid(True)

    # 3. ê°€ì†ë„ í‰ê· 
    axes[2].plot(x, np.mean(actual_acceleration, axis=1), label="Actual", color='blue')
    axes[2].plot(x, np.mean(ideal_acceleration, axis=1), label="Ideal", color='red', linestyle='--')
    axes[2].set_title("Acceleration Comparison")
    axes[2].legend()
    axes[2].grid(True)

    # 4. ë‹¨ê³„ ì „í™˜ ë³€í™”ëŸ‰
    axes[3].plot(x[:-1], avg_actual_transition, label="Actual", color='blue')
    axes[3].plot(x[:-1], avg_ideal_transition, label="Ideal", color='red', linestyle='--')
    axes[3].set_title("Phase Transition Î” (Mean of Joint Differences)")
    axes[3].legend()
    axes[3].grid(True)

    # âœ… 5. ê°ë„ ë³€í™”ëŸ‰
    axes[4].plot(x[1:], angle_change_actual, label="Actual", color='blue')
    axes[4].plot(x[1:], angle_change_ideal, label="Ideal", color='red', linestyle='--')
    axes[4].set_title("Angle Change Rate (L2 Norm per Frame)")
    axes[4].legend()
    axes[4].grid(True)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(save_path)
    plt.close()
    print(f"âœ… ì‹œê°í™” ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")

def estimate_phases(joint_angles):
    """
    joint_angles (N x J) ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„ì‹œ ë‹¨ê³„ êµ¬ê°„ì„ ë‹¨ìˆœ ìƒì„± (ì˜ˆì‹œìš©).
    ë‚˜ì¤‘ì— ìˆ˜ì • ê°€ëŠ¥.
    """
    # ë‹¨ìˆœíˆ ê°ë„ í‰ê· ì˜ ë³€í™”ëŸ‰ìœ¼ë¡œ ë‹¨ê³„ êµ¬ë¶„ (ì˜ˆì‹œ)
    diff = np.abs(np.gradient(np.mean(joint_angles, axis=1)))
    threshold = np.percentile(diff, 60)
    phases = (diff > threshold).astype(int)
    return np.cumsum(phases) % 5  # ìµœëŒ€ 5ë‹¨ê³„ë¡œ ìˆœí™˜




# 7. ë‰´ë„¤ì˜¤ìŠˆí¼ ì• ë‹ˆë©”ì´ì…˜
def save_ideal_angles_to_csv(ideal_trajectory, save_path="ideal_angles.csv"):
    """
    generate_ideal_trajectory()ë¡œ ìƒì„±í•œ ì´ìƒ ê¶¤ì  (ê´€ì ˆ ê°ë„ ì‹œí€€ìŠ¤)ì„ CSVë¡œ ì €ì¥
    - ê° í”„ë ˆì„ë§ˆë‹¤ 10ê°œ ê°ë„ë¥¼ ì €ì¥
    """
    if not ideal_trajectory or not isinstance(ideal_trajectory, list):
        print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
        return
    
    df = pd.DataFrame(ideal_trajectory, columns=[
        f"angle_{i}" for i in range(len(ideal_trajectory[0]))
    ])
    df.to_csv(save_path, index=False)
    print(f"âœ… ì´ìƒ ê¶¤ì  CSV ì €ì¥ ì™„ë£Œ: {save_path}")

def save_subset_landmarks_csv(input_csv_path, output_csv_path):
    """
    ê¸°ì¡´ ì¢Œí‘œ CSVì—ì„œ ì£¼ìš” ê´€ì ˆ(14ê°œ)ì˜ x, y, z ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ CSVë¡œ ì €ì¥
    """
    df = pd.read_csv(input_csv_path)

    key_joints = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30]
    columns_to_keep = []

    for i in key_joints:
        columns_to_keep.extend([
            f"landmark_{i}_x",
            f"landmark_{i}_y",
            f"landmark_{i}_z"
        ])

    subset_df = df[columns_to_keep]
    subset_df.to_csv(output_csv_path, index=False)
    print(f"âœ… ì£¼ìš” ê´€ì ˆë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥ ì™„ë£Œ: {output_csv_path}")

def draw_pose_from_points(img, points, offset_x=0, color=(0, 255, 0)):
    """
    10ê°œ í¬ì¸íŠ¸(ê°ë„ ê¸°ë°˜)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ëŒ í˜•íƒœì˜ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    ì¸ë±ìŠ¤ ìˆœì„œ ê¸°ì¤€: [LK, RK, LE, RE, LS, RS, LH, RH, LA, RA]
    """

    connections = [
        (4, 6), (6, 0), (0, 8),  # ì™¼ìª½ ì–´ê¹¨ â†’ ì—‰ë©ì´ â†’ ë¬´ë¦ â†’ ë°œëª©
        (5, 7), (7, 1), (1, 9),  # ì˜¤ë¥¸ìª½ ì–´ê¹¨ â†’ ì—‰ë©ì´ â†’ ë¬´ë¦ â†’ ë°œëª©
        (4, 5),                 # ì–´ê¹¨ ì—°ê²°
        (4, 2), (5, 3),         # ì–´ê¹¨ â†’ íŒ”ê¿ˆì¹˜
    ]

    for x, y in points:
        x = np.clip(x + offset_x, 0, img.shape[1] - 1)
        y = np.clip(y, 0, img.shape[0] - 1)
        cv2.circle(img, (x, y), 5, color, -1)

    for start, end in connections:
        try:
            x1, y1 = points[start]
            x2, y2 = points[end]
            cv2.line(img, (x1 + offset_x, y1), (x2 + offset_x, y2), color, 2)
        except:
            continue



def angle_to_point(angle):
    rad = np.radians(angle)
    x = np.cos(rad)
    y = np.sin(rad)
    z = angle / 180.0
    return x, y, z

def project_point(x, y, z, scale=300, cx=360, cy=520):
    z = -z
    factor = 2.0 / (2.0 - z + 1e-6)
    x2d = int(x * factor * scale + cx)
    y2d = int(y * factor * scale + cy)
    return x2d, y2d

def animate_full_pose_with_ideal_overlay(actual_df, ideal_df, save_path, preview=False):
    import cv2
    import numpy as np

    ACTUAL_POSE_CONNECTIONS = [
        (11, 13), (13, 15), (12, 14), (14, 16),
        (23, 11), (24, 12), (23, 24),
        (23, 25), (25, 27), (27, 29),
        (24, 26), (26, 28), (28, 30)
    ]

    angle_groups = {
        "left_arm": [13, 15],
        "right_arm": [14, 16],
        "left_leg": [25, 27, 29],
        "right_leg": [26, 28, 30]
    }

    # ìƒˆë¡œ ì¶”ê°€: ê´€ì ˆìŒ ë²¡í„° ì •ë³´
    pair_indices = [
        (13, 15), (14, 16),
        (11, 13), (12, 14),
        (23, 25), (24, 26),
        (25, 27), (26, 28),
        (11, 23), (12, 24),
        (27, 29), (28, 30),
    ]

    h, w = 1040, 720
    out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), 10, (w, h))
    num_frames = min(len(actual_df), len(ideal_df))

    key_joints = [11,12,13,14,15,16,23,24,25,26,27,28,29,30]

    for i in range(num_frames):
        img = np.zeros((h, w, 3), dtype=np.uint8)

        actual_points = {}
        for j in key_joints:
            try:
                x = float(actual_df.iloc[i][f"landmark_{j}_x"])
                y = float(actual_df.iloc[i][f"landmark_{j}_y"])
                x2d = int((x * 300) + 360)
                y2d = int((y * 300) + 520)
                actual_points[j] = (x2d, y2d)
            except:
                actual_points[j] = (0, 0)

        # ğŸ§  ì´ìƒì  ì¢Œí‘œ ìƒì„± (ê´€ì ˆìŒ ë²¡í„° + ê°ë„ ê¸°ë°˜)
        angle_values = list(ideal_df.iloc[i])
        angle_idx = 0
        ideal_points = actual_points.copy()

        for (j1, j2) in pair_indices:
            if angle_idx >= len(angle_values):
                break
            try:
                angle = float(angle_values[angle_idx])
                angle_idx += 1

                # ì‹¤ì œ ë²¡í„° ë°©í–¥ ê³„ì‚°
                x1, y1 = actual_df.iloc[i][f"landmark_{j1}_x"], actual_df.iloc[i][f"landmark_{j1}_y"]
                x2, y2 = actual_df.iloc[i][f"landmark_{j2}_x"], actual_df.iloc[i][f"landmark_{j2}_y"]
                dx, dy = x2 - x1, y2 - y1
                norm = np.sqrt(dx ** 2 + dy ** 2) + 1e-6
                dx, dy = dx / norm, dy / norm

                # ê´€ì ˆ ë°©í–¥ ë²¡í„°ë¡œ ì´ìƒ ì¢Œí‘œ ìƒì„±
                magnitude = angle / 180.0 * 0.1
                base_x, base_y = float(actual_df.iloc[i][f"landmark_{j1}_x"]), float(actual_df.iloc[i][f"landmark_{j1}_y"])
                ideal_x = base_x + dx * magnitude
                ideal_y = base_y + dy * magnitude

                # ì‹œê°í™”ìš© 2D íˆ¬ì˜
                x2d = int((ideal_x * 300) + 360 - 20)  # ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì‚´ì§ ë³´ì´ê²Œ
                y2d = int((ideal_y * 300) + 520)
                ideal_points[j2] = (x2d, y2d)

            except Exception as e:
                continue

        # ì‹¤ì œ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰)
        for start, end in ACTUAL_POSE_CONNECTIONS:
            pt1 = actual_points.get(start, (0, 0))
            pt2 = actual_points.get(end, (0, 0))
            if pt1 != (0, 0) and pt2 != (0, 0):
                cv2.line(img, pt1, pt2, (0, 255, 0), 2)

        # ì´ìƒì  ì—°ê²°ì„  ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
        for group in angle_groups.values():
            for j in range(len(group) - 1):
                a, b = group[j], group[j+1]
                pt1 = ideal_points.get(a, (0, 0))
                pt2 = ideal_points.get(b, (0, 0))
                if pt1 != (0, 0) and pt2 != (0, 0):
                    cv2.line(img, pt1, pt2, (0, 0, 255), 2)

        # ì  ê·¸ë¦¬ê¸°
        for j, pt in actual_points.items():
            if pt != (0, 0):
                cv2.circle(img, pt, 3, (0, 255, 0), -1)
        for j in ideal_points:
            pt = ideal_points[j]
            if pt != (0, 0):
                cv2.circle(img, pt, 5, (0, 0, 255), -1)

        cv2.putText(img, "Red: Ideal (from joint pairs) | Green: Actual", (20, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (200, 200, 200), 2)

        out.write(img)
        if preview:
            cv2.imshow("Pose Overlay", img)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    out.release()
    if preview:
        cv2.destroyAllWindows()

    return save_path





def project_relative_to_actual(x, y, z, actual_origin, is_leg=False):
    ax, ay = actual_origin
    # ë‹¤ë¦¬ëŠ” ë” ì‘ì€ ìŠ¤ì¼€ì¼ë¡œ ëœ íŠ€ê²Œ ë³´ì •
    scale_xy = 30 if is_leg else 45
    scale_z = 10 if is_leg else 18
    x2d = int(ax + x * scale_xy)
    y2d = int(ay + y * scale_xy + z * scale_z)
    return x2d, y2d


def extract_joint_angle_sequence(df, start, end):
    angle_seq = []
    for i in range(start, end):
        try:
            frame = [(df[f'landmark_{j}_x'].iloc[i], 
                      df[f'landmark_{j}_y'].iloc[i], 
                      df[f'landmark_{j}_z'].iloc[i]) for j in range(33)]
            angles = [
                compute_angle(frame[23], frame[25], frame[27]),
                compute_angle(frame[24], frame[26], frame[28]),
                compute_angle(frame[11], frame[13], frame[15]),
                compute_angle(frame[12], frame[14], frame[16]),
                compute_angle(frame[13], frame[11], frame[23]),
                compute_angle(frame[14], frame[12], frame[24]),
                compute_angle(frame[11], frame[23], frame[25]),
                compute_angle(frame[12], frame[24], frame[26]),
                compute_angle(frame[25], frame[27], frame[29]),
                compute_angle(frame[26], frame[28], frame[30]),
            ]
            angle_seq.append(angles)
        except Exception as e:
            print(f"âŒ ê´€ì ˆ ê°ë„ ì¶”ì¶œ ì‹¤íŒ¨ (í”„ë ˆì„ {i}): {e}")
            continue
    return angle_seq

def interpolate_trajectory_by_phase_progress(trajectory, phase_progress, target_length):
    """
    ê´€ì ˆ ê°ë„ ê¶¤ì ì„ ë‹¨ê³„ë³„ ì§„í–‰ë¥  ê¸°ì¤€ìœ¼ë¡œ target_length ê¸¸ì´ë¡œ ë³´ê°„.
    
    trajectory: í”„ë ˆì„ë³„ phase ì¸ë±ìŠ¤ ë°°ì—´
    phase_progress: ê° ë‹¨ê³„ì˜ ë¹„ìœ¨
    target_length: ëª©í‘œ í”„ë ˆì„ ìˆ˜
    """
    original_length = len(trajectory)
    if original_length < 2 or target_length < 2:
        return trajectory

    # ê° ë‹¨ê³„ì˜ ì‹œì‘ê³¼ ë ì¸ë±ìŠ¤ë¥¼ ì›ë³¸/ëª©í‘œ í”„ë ˆì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
    original_phase_boundaries = np.cumsum([0] + [int(p * original_length) for p in phase_progress])
    target_phase_boundaries = np.cumsum([0] + [int(p * target_length) for p in phase_progress])

    # ëì  ë³´ì •
    original_phase_boundaries[-1] = original_length
    target_phase_boundaries[-1] = target_length

    interpolated_traj = []

    for i in range(len(phase_progress)):
        start_o, end_o = original_phase_boundaries[i], original_phase_boundaries[i+1]
        start_t, end_t = target_phase_boundaries[i], target_phase_boundaries[i+1]

        segment = trajectory[start_o:end_o]

        if len(segment) < 2:
            segment = [segment[0]] * 2  # ìµœì†Œí•œ 2ê°œì˜ ê°’ìœ¼ë¡œ ë³µì‚¬

        x_old = np.linspace(0, 1, len(segment))
        x_new = np.linspace(0, 1, end_t - start_t)

        # ë‹¨ê³„ì˜ ê°ë„ë¥¼ ë³´ê°„
        interpolator = interp1d(x_old, segment, kind='linear', fill_value="extrapolate")
        interpolated_segment = interpolator(x_new)

        interpolated_traj.extend(interpolated_segment.tolist())

    # ë³´ì •í•˜ì—¬ ìµœì¢… ê¸¸ì´ ë§ì¶”ê¸°
    while len(interpolated_traj) < target_length:
        interpolated_traj.append(interpolated_traj[-1])

    return interpolated_traj[:target_length]

# 8. í”„ë¡¬í”„íŠ¸ ìƒì„±

# === ìœ„ì¹˜ ê¸°ë°˜ ì˜¤ì°¨ ë¶„ì„ (ì‹¤ì œ ë°©í–¥ ê¸°ë°˜) ===
def compute_projected_ideal_points_realistic(actual_df, ideal_df):
    key_joints = [11,12,13,14,15,16,23,24,25,26,27,28,29,30]
    pair_indices = [
        (13, 15), (14, 16),  # íŒ”ê¿ˆì¹˜
        (11, 13), (12, 14),  # ì–´ê¹¨
        (23, 25), (24, 26),  # ì—‰ë©ì´
        (25, 27), (26, 28),  # ë¬´ë¦
        (11, 23), (12, 24),     # ì–´ê¹¨ â†’ í™ (Hip ì¢Œí‘œ ìƒì„±ìš©)
        (27, 29), (28, 30),
    ]

    ideal_points_per_frame = []

    for i in range(len(ideal_df)):
        actual_points = {}
        for j in key_joints:
            try:
                x = actual_df.loc[i, f"landmark_{j}_x"]
                y = actual_df.loc[i, f"landmark_{j}_y"]
                z = actual_df.loc[i, f"landmark_{j}_z"]
                actual_points[j] = np.array([x, y, z])
            except:
                actual_points[j] = np.array([0, 0, 0])

        angles = ideal_df.iloc[i].values
        ideal_frame_points = {}

        for idx, (j1, j2) in enumerate(pair_indices):
            if idx >= len(angles): continue
            base = actual_points[j1]
            direction = actual_points[j2] - actual_points[j1]
            norm = np.linalg.norm(direction)
            if norm == 0:
                direction = np.array([1, 0, 0])
            else:
                direction /= norm
            magnitude = angles[idx] / 180.0 * 0.1
            new_point = base + direction * magnitude
            ideal_frame_points[j2] = tuple(new_point)

        for j in key_joints:
            if j not in ideal_frame_points:
                ideal_frame_points[j] = tuple(actual_points[j])

        ideal_points_per_frame.append([ideal_frame_points[j] for j in key_joints])

    return ideal_points_per_frame

def summarize_joint_errors_for_feedback(
        error_df, 
        joint_labels, 
        actual_points_per_frame, 
        ideal_points_per_frame, 
        SessionID:str,
        UserId:str,
        ExercisesName:str,
        frame_group_thresh=3
    ):

    joint_thresholds = {
        joint: np.mean(error_df[joint]) + 1.5 * np.std(error_df[joint])
        for joint in joint_labels
    }

    frame_flags = defaultdict(list)
    for _, row in error_df.iterrows():
        frame = int(row["frame"])
        for joint in joint_labels:
            if row[joint] > joint_thresholds[joint]:
                frame_flags[frame].append((joint, row[joint]))

    def group_frames(frames):
        grouped, temp, last = [], [], None
        for f in sorted(frames):
            if last is None or f == last + 1:
                temp.append(f)
            else:
                grouped.append(temp)
                temp = [f]
            last = f
        if temp:
            grouped.append(temp)
        return grouped

    def get_direction_vector(diff_vec):
        directions = []
        if abs(diff_vec[0]) > 0.01:
            directions.append("to the right" if diff_vec[0] > 0 else "to the left")
        if abs(diff_vec[1]) > 0.01:
            directions.append("upward" if diff_vec[1] > 0 else "downward")
        if abs(diff_vec[2]) > 0.01:
            directions.append("forward" if diff_vec[2] > 0 else "backward")
        return ", ".join(directions) if directions else "minor deviation"

    def format_error_detail(avg_error, direction_str):
        if direction_str == "minor deviation":
            return "No significant deviation detected."
        if avg_error < 0.02:
            level = "slightly"
        elif avg_error < 0.05:
            level = "a bit"
        elif avg_error < 0.1:
            level = "moderately"
        elif avg_error < 0.2:
            level = "significantly"
        else:
            level = "severely"
        return f"{level} deviated {direction_str}"

    grouped_frames = group_frames(frame_flags.keys())
    result = []
    result.append({
        "SessionID": f"{SessionID}",
        "UserID": f"{UserId}",
        "ExerciseName": f"{ExercisesName}",
    })
    for group in grouped_frames:
        if len(group) < frame_group_thresh:
            continue

        joint_stats = defaultdict(list)
        joint_directions = defaultdict(list)
        for f in group:
            for joint, err in frame_flags[f]:
                joint_stats[joint].append(err)
                j_index = joint_labels.index(joint)
                actual = np.array(actual_points_per_frame[f][j_index])
                ideal = np.array(ideal_points_per_frame[f][j_index])
                diff = actual - ideal
                joint_directions[joint].append(diff)

        summary = []
        for joint, errors in joint_stats.items():
            if len(errors) >= frame_group_thresh:
                avg_error = round(np.mean(errors), 4)
                diffs = np.array(joint_directions[joint])
                avg_vec = np.mean(diffs, axis=0)
                direction_str = get_direction_vector(avg_vec)
                error_detail = format_error_detail(avg_error, direction_str)

                summary.append({
                    "name": joint,
                    "error_detail": error_detail
                })

        if summary:
            result.append({
                "range": f"Frame {group[0]}~{group[-1]}",
                "joints": summary,
                "comment": "Multiple joint deviations detected during this interval."
            })

    return result

def get_user_center_from_frame(frame: np.ndarray) -> tuple:
    """
    Extracts the user's pelvis center from a frame using MediaPipe Pose.
    Returns (x, y) normalized coordinates or None if detection fails.
    """
    mp_pose = mp.solutions.pose
    with mp_pose.Pose(static_image_mode=True) as pose:
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(rgb_frame)

        if not results.pose_landmarks:
            return None

        landmarks = results.pose_landmarks.landmark
        if len(landmarks) < 25:
            return None

        # landmarks 23: left_hip, 24: right_hip
        center_x = (landmarks[23].x + landmarks[24].x) / 2
        center_y = (landmarks[23].y + landmarks[24].y) / 2

        return (center_x, center_y)

def generate_feedback_overlay_images(
    video_path: str,
    feedback_json_path: str,
    actual_df: pd.DataFrame,
    ideal_df: pd.DataFrame,
    output_dir: str
):
    os.makedirs(os.path.join(output_dir, "frame_feedback"), exist_ok=True)
    key_joints = [11,12,13,14,15,16,23,24,25,26,27,28,29,30]
    connections = [(11,13),(13,15),(12,14),(14,16),(23,25),
                   (25,27),(27,29),(24,26),(26,28),(28,30)]

    with open(feedback_json_path, "r", encoding="utf-8") as f:
        feedback_data = json.load(f)

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    for item in feedback_data:
        if "range" not in item:
            continue

        start, end = map(int, item["range"].replace("Frame ", "").split("~"))
        if (end - start + 1) < 20:
            continue

        target_frame = (start + end) // 2
        if target_frame >= total_frames:
            continue

        cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
        success, frame = cap.read()
        if not success:
            print(f"âŒ Frame {target_frame} capture failed")
            continue
        h, w = frame.shape[:2]

        # âœ… ì‚¬ìš©ì ì¤‘ì‹¬ ì¢Œí‘œ êµ¬í•˜ê¸°
        user_center = get_user_center_from_frame(frame)
        if user_center is None:
            print(f"âŒ Failed to detect user center in Frame {target_frame}")
            continue

        user_center_x, user_center_y = user_center
        offset_x = int((1.0 - user_center_x) * w)
        offset_y = h // 2 - int(user_center_y * h)
        #print(f"{offset_x},{offset_y}")

        def to_pixel_coords(x, y):
            return (int(x * w + offset_x), int(y * h + offset_y))

        actual_points = []
        ideal_points = []

        for i, j in enumerate(key_joints):
            try:
                ax = actual_df.loc[target_frame, f"landmark_{j}_x"]
                ay = actual_df.loc[target_frame, f"landmark_{j}_y"]
                actual_points.append((ax, ay))
            except:
                actual_points.append((0, 0))

            try:
                angle = ideal_df.iloc[target_frame, i]
                dx = 0.05 if j % 2 == 0 else -0.05
                dy = -0.05
                ix = ax + dx * (angle / 180)
                iy = ay + dy * (angle / 180)
                ideal_points.append((ix, iy))
            except:
                ideal_points.append((0, 0))

        actual_points_pixel = [to_pixel_coords(x, y) for (x, y) in actual_points]
        ideal_points_pixel = [to_pixel_coords(x, y) for (x, y) in ideal_points]

        overlay = frame.copy()

        # draw actual (green)
        for (i, j) in connections:
            i1 = key_joints.index(i)
            i2 = key_joints.index(j)
            if actual_points[i1] != (0,0) and actual_points[i2] != (0,0):
                cv2.line(overlay, actual_points_pixel[i1], actual_points_pixel[i2], (0,255,0), 2)
        for pt in actual_points_pixel:
            if pt != (0,0): cv2.circle(overlay, pt, 4, (0,255,0), -1)

        # draw ideal (red)
        for (i, j) in connections:
            i1 = key_joints.index(i)
            i2 = key_joints.index(j)
            if ideal_points[i1] != (0,0) and ideal_points[i2] != (0,0):
                cv2.line(overlay, ideal_points_pixel[i1], ideal_points_pixel[i2], (0,0,255), 2)
        for pt in ideal_points_pixel:
            if pt != (0,0): cv2.circle(overlay, pt, 4, (0,0,255), -1)

        cv2.putText(overlay, f"Frame {target_frame}", (30, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)

        save_path = os.path.join(output_dir)
        cv2.imwrite(save_path, overlay)
        #print(f"âœ… Saved: {save_path}")

    cap.release()


def build_gpt_prompt_from_summary(
    feedback_data: list
) -> str:
    # 1. Parse metadata (assumed to be the first dictionary with "ExerciseName")
    meta = None
    for entry in feedback_data:
        if "ExerciseName" in entry:
            meta = entry
            break

    if meta is None:
        raise ValueError("No metadata with 'ExerciseName' found in feedback_data.")

    exercise_name = meta.get("ExerciseName", "Unknown Exercise")
    exercise_description = meta.get("ExerciseDescription", "No description provided.")
    ideal_pose_bullet_points = meta.get("IdealPose", [])

    # 2. Construct prompt string with manual line breaks
    prompt = ""
    prompt += f"ğŸ§  You are a movement feedback coach. The user is performing '{exercise_name}'.\n\n"
    prompt += f"Exercise Description: {exercise_description}\n\n"
    prompt += "Ideal Form:\n"
    for bullet in ideal_pose_bullet_points:
        prompt += f"â€¢ {bullet}\n"

    prompt += "\nDetected Deviations:\n"
    
    # 3. Add deviation summaries (skip any metadata-like entries)
    for section in feedback_data:
        if "range" not in section or "joints" not in section:
            continue
        prompt += f"\n[ğŸ“ {section['range']}]\n"
        for joint in section["joints"]:
            prompt += f"- {joint['name']}: {joint['error_detail']}\n"

    # 4. GPT instruction
    prompt += (
        "\n\nBased on the above, please explain in three parts:\n"
        "1. What is incorrect with the user's form\n"
        "2. Why this might be happening\n"
        "3. How to correct it (include light stretches or drills if helpful)\n\n"
        "Avoid technical jargon. Make your explanation simple and actionable for beginners.\n"
    )

    return prompt


# 9. ë©”ì¸ ì‹¤í–‰
def main():

    if len(sys.argv) != 5:
        print("â—ì‚¬ìš©ë²•: python analysis.py [ì˜ìƒê²½ë¡œ] [ì¶œë ¥ì´ë¯¸ì§€ê²½ë¡œ] [ìš´ë™ì´ë¦„] [ì„ì‹œíŒŒì¼ì¼]")
        sys.exit(1)

    video_path = sys.argv[1]
    output_dir = sys.argv[2]
    exercise_name = sys.argv[3]
    temp_path = sys.argv[4]
    sub_exercise = f"{exercise_name}v2"

    video_filename = os.path.splitext(os.path.basename(video_path))[0]
    csv_path = f"{temp_path}/{video_filename}.csv"
    os.makedirs(temp_path, exist_ok=True)

    extracted_csv = extract_landmarks(video_path, csv_path)
    print(f"ğŸ” extract_landmarks ê²°ê³¼: {extracted_csv}")
    print(f"ğŸ” CSV Generated: {csv_path}, Proceeding to Similarity Analysis...")

    df = load_and_process_csv(csv_path)
    if df is None or df.empty:
        logging.error("âŒ CSV íŒŒì¼ ë¡œë”© ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return

    angle_features, velocity_features, acceleration_features = compute_joint_angles_with_derivatives(df)
    if angle_features.size == 0:
        logging.error("âŒ ê´€ì ˆ ê°ë„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨.")
        return

    segments = detect_repetition_intervals(angle_features, velocity_features, acceleration_features)
    if not segments:
        logging.error("âŒ ìš´ë™ ë°˜ë³µ êµ¬ê°„ ê²€ì¶œ ì‹¤íŒ¨.")
        return
    print(f"ğŸ” ê²€ì¶œëœ ìš´ë™ ë°˜ë³µ ìˆ˜: {len(segments)}íšŒ")

    # StepSplit ê¸°ì¤€ ë°ì´í„° ë¡œë“œ
    split_criteria_path = f"./data/models/StepSplit/{sub_exercise}_combined_step_split_criteria.pkl"
    if not os.path.exists(split_criteria_path):
        logging.error("âŒ ê¸°ì¤€ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(split_criteria_path, "rb") as f:
        split_criteria = pickle.load(f)

    cluster_centers = np.hstack([
        split_criteria["angles"],
        split_criteria["velocities"],
        split_criteria["accelerations"]
    ])
    ideal_phase_lengths = split_criteria["phase_lengths"]
    ideal_phase_progress = split_criteria["phase_progress"]

    # ìˆ˜ì •ëœ ì´ìƒì  ê¶¤ì  ë¡œë“œ (ê´€ì ˆë³„ë¡œ ì €ì¥)
    ideal_trajectory_path = f"./data/models/analysistrajectory/{sub_exercise}/{sub_exercise}_ideal_trajectory.pkl"
    if not os.path.exists(ideal_trajectory_path):
        logging.error("âŒ ì´ìƒì  ê¶¤ì  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(ideal_trajectory_path, "rb") as f:
        ideal_joint_data = pickle.load(f)  # ê´€ì ˆë³„ ë°ì´í„° ë¡œë“œ

    joint_names = [f"joint_{i}" for i in range(10)]
    actual_all_angles = []
    ideal_all_angles = []
    total_similarity = []

    for i, (start, end) in enumerate(segments):
        actual_segment_angles = angle_features[start:end]
        actual_segment_velocities = velocity_features[start:end]
        actual_segment_accelerations = acceleration_features[start:end]

        actual_all_angles.extend(actual_segment_angles.tolist())

        # ê´€ì ˆë³„ë¡œ ë³´ê°„ëœ ì´ìƒì  ê¶¤ì  ìƒì„±
        generated_ideal_points = []
        for joint in joint_names:
            joint_data = ideal_joint_data[joint]
            ideal_trajectory_phases = joint_data["ideal_trajectory"]
            ideal_phase_progress_segment = joint_data["phase_progress"]

            # ë³´ê°„ëœ ì´ìƒì  ê°ë„ ìƒì„± (ê¸°ì¤€ ë°ì´í„°ë¥¼ ë‹¨ê³„ë³„ë¡œ ë³´ê°„)
            interpolated_ideal_angles = interpolate_trajectory_by_phase_progress(
                ideal_trajectory_phases,
                ideal_phase_progress_segment,
                target_length=(end - start)
            )
            generated_ideal_points.append(interpolated_ideal_angles)

        generated_ideal_points = np.array(generated_ideal_points).T
        ideal_all_angles.extend(generated_ideal_points.tolist())

        # ë‹¨ê³„ ê³„ì‚° ë° ìœ ì‚¬ë„ ë¶„ì„
        try:
            computed_phases, computed_progress, _ = classify_phases(
                actual_segment_angles, 
                actual_segment_velocities, 
                actual_segment_accelerations, 
                cluster_centers, 
                ideal_phase_lengths,
                ideal_trajectory_phases
            )

            similarity = compare_phase_similarity(
                computed_phases,
                ideal_trajectory_phases,
                actual_segment_velocities,
                split_criteria["velocities"],
                actual_segment_accelerations,
                split_criteria["accelerations"],
                computed_progress,
                ideal_phase_progress_segment,
                joint_data["phase_transitions"],  # ë‹¨ê³„ ì „í™˜ ì •ë³´ ì‚¬ìš©
                actual_segment_angles,
                generated_ideal_points
            )
            total_similarity.append(similarity)

        except Exception as e:
            logging.error(f"âŒ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            total_similarity.append(0)

        output_path = os.path.join(temp_path, f"babellow_trajectory_{i+1}.png")
        plot_trajectory_comparison(
            actual_segment_angles,
            generated_ideal_points,
            save_path=output_path,
            exercise_name="Babellow"
        )

    try:
        overall_similarity = np.average(
            total_similarity, 
            weights=[(end - start) for start, end in segments]
        )
    except Exception as e:
        logging.error(f"âŒ ì „ì²´ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        overall_similarity = np.mean(total_similarity)
    print(f"\nğŸ”¥ ì „ì²´ í‰ê·  ìœ ì‚¬ë„: {overall_similarity:.2f}%")

    ideal = os.path.join(temp_path, "ideal_angles.csv")
    actual = os.path.join(temp_path, "actual_angles.csv")

    # ê²°ê³¼ CSV ì €ì¥
    if actual_all_angles and ideal_all_angles:
        save_ideal_angles_to_csv(ideal_all_angles, ideal)
        save_ideal_angles_to_csv(actual_all_angles, actual)

        # ì „ì²´ í”„ë ˆì„ landmark CSV ë¡œë“œ
        actual_landmark_df = pd.read_csv(csv_path)

        # ì‹œê°í™” ì˜ìƒ ìƒì„±
        save_video_path = os.path.join(temp_path, "final_pose_comparison.mp4")
        animate_full_pose_with_ideal_overlay(
            actual_df=actual_landmark_df,
            ideal_df=pd.read_csv(ideal),
            save_path=save_video_path,
            preview=True
        )

        print("\nğŸ“ ì£¼ìš” ê´€ì ˆë³„ ìœ„ì¹˜ ë¹„êµ ì‹œì‘...")
        key_joints = [11,12,13,14,15,16,23,24,25,26,27,28,29,30]
        actual_points_per_frame = []
        for i in range(len(actual_landmark_df)):
            points = []
            for j in key_joints:
                x = actual_landmark_df.loc[i, f"landmark_{j}_x"]
                y = actual_landmark_df.loc[i, f"landmark_{j}_y"]
                z = actual_landmark_df.loc[i, f"landmark_{j}_z"]
                points.append((x, y, z))
            actual_points_per_frame.append(points)

        ideal_angles_df = pd.read_csv(ideal)
        ideal_points_per_frame = compute_projected_ideal_points_realistic(actual_landmark_df, ideal_angles_df)

        joint_errors = {j: [] for j in range(10)}
        for f in range(len(ideal_points_per_frame)):
            for j in range(10):
                ax, ay, az = actual_points_per_frame[f][j]
                ix, iy, iz = ideal_points_per_frame[f][j]
                dist = np.sqrt((ax - ix)**2 + (ay - iy)**2 + (az - iz)**2)
                joint_errors[j].append(dist)

        print("ğŸ“Š ê´€ì ˆë³„ í‰ê·  ìœ„ì¹˜ ì˜¤ì°¨ (ë‹¨ìœ„: ê±°ë¦¬)")
        joint_labels = [
            "Left Knee", "Right Knee", "Left Elbow", "Right Elbow",
            "Left Shoulder", "Right Shoulder", "Left Hip", "Right Hip",
            "Left Ankle", "Right Ankle"
        ]
        for j in range(10):
            avg_error = np.mean(joint_errors[j])
            print(f"{joint_labels[j]:<15}: {avg_error:.4f}")
            
        # === ğŸ“„ í”„ë ˆì„ë³„ ì˜¤ì°¨ CSV ì €ì¥ ===
        error_csv_path = os.path.join(temp_path, "joint_errors_by_frame.csv")
        frame_data = []
        for f in range(len(joint_errors[0])):
            row = {"frame": f}
            for j in range(10):
                row[joint_labels[j]] = joint_errors[j][f]
            frame_data.append(row)
        error_df = pd.DataFrame(frame_data)
        error_df.to_csv(error_csv_path, index=False)
        print(f"\nğŸ“„ í”„ë ˆì„ë³„ ê´€ì ˆ ì˜¤ì°¨ CSV ì €ì¥ ì™„ë£Œ: {error_csv_path}")

        # === âš ï¸ ì˜¤ì°¨ í° í”„ë ˆì„ íƒì§€ ===
        print("\nâš ï¸ ì˜¤ì°¨ê°€ í° í”„ë ˆì„ ë° ê´€ì ˆ íƒì§€ ì¤‘...")

        # ê´€ì ˆë³„ í‰ê·  + í‘œì¤€í¸ì°¨ ê¸°ë°˜ threshold ê³„ì‚°
        joint_thresholds = {}
        for j in range(10):
            joint_mean = np.mean(joint_errors[j])
            joint_std = np.std(joint_errors[j])
            joint_thresholds[joint_labels[j]] = joint_mean + 1.5 * joint_std

        flagged = []

        for idx, row in error_df.iterrows():
            flagged_joints = []
            for j, joint in enumerate(joint_labels):
                error = row[joint]
                if error > joint_thresholds[joint]:
                    flagged_joints.append((joint, error))
            if len(flagged_joints) >= 3:  # ë™ì‹œì— 3ê°œ ì´ìƒ í‹€ë ¸ì„ ë•Œë§Œ í‘œì‹œ
                print(f"- Frame {int(row['frame'])}:")
                for joint, err in flagged_joints:
                    print(f"   â€¢ {joint}: {err:.4f}")
                flagged.append(idx)

        print(f"\nì´ {len(flagged)}ê°œ í”„ë ˆì„ì—ì„œ ì˜¤ì°¨ê°€ í° ê´€ì ˆ ë‹¤ìˆ˜ ë°œê²¬ë¨.")
        session_id = "c51f71e1-749a-4f9b-9f55-xxxxxx"
        user_id = "test_user_001"
        exercise_name = "ballow"
        feedback_summary = summarize_joint_errors_for_feedback(
            error_df, joint_labels,
            actual_points_per_frame,    # â† ì¶”ê°€
            ideal_points_per_frame,      # â† ì¶”ê°€
            session_id,
            user_id,
            exercise_name
        )
        json_path = os.path.join(temp_path, "feedback_summary.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(feedback_summary, f, ensure_ascii=False, indent=2)

        print(json.dumps(feedback_summary))
        #print(f"\nâœ… í”¼ë“œë°± ìš”ì•½ JSON ì €ì¥ ì™„ë£Œ: {json_path}")

        feedback_data = [{
            "SessionID": session_id,
            "UserID": user_id,
            "ExerciseName": exercise_name,
            "ExerciseDescription": "This exercise strengthens the biceps...",
            "IdealPose": [
                "Keep your elbows fixed at your sides throughout the movement.",
                "Avoid moving your shoulders; they should remain stable.",
                "Maintain a neutral wrist position without bending.",
                "The elbow flexion angle should range between approximately 50 and 140 degrees."
            ]
        }] + feedback_summary

        # feedback_summaryëŠ” summarize_joint_errors_for_feedback() ê²°ê³¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
        prompt = build_gpt_prompt_from_summary(feedback_data)

        # íŒŒì¼ë¡œ ì €ì¥í•´ë„ OK
        gpt_prompt_path = os.path.join(temp_path, "gpt_prompt.json")
        with open(gpt_prompt_path, "w", encoding="utf-8") as f:
            json.dump({ "prompt": prompt }, f, ensure_ascii=False, indent=2)

        with open(os.path.join(temp_path, "gpt_prompt.txt"), "w", encoding="utf-8") as f:
            f.write(prompt)

        #print(f"âœ… GPT í”„ë¡¬í”„íŠ¸ JSON ì €ì¥ ì™„ë£Œ: {gpt_prompt_path}")
        generate_feedback_overlay_images(
            video_path=video_path,
            feedback_json_path=f"{temp_path}/feedback_summary.json",
            actual_df=actual_landmark_df,
            ideal_df=ideal_angles_df,
            output_dir=output_dir
        )
        
if __name__ == "__main__":
    main()
